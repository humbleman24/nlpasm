{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 25.0,
  "eval_steps": 500,
  "global_step": 37900,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.32981530343007914,
      "grad_norm": 2.9344077110290527,
      "learning_rate": 8.357519788918206e-05,
      "loss": 2.5085,
      "step": 500
    },
    {
      "epoch": 0.6596306068601583,
      "grad_norm": 4.096022129058838,
      "learning_rate": 6.70844327176781e-05,
      "loss": 2.4308,
      "step": 1000
    },
    {
      "epoch": 0.9894459102902374,
      "grad_norm": 3.9939937591552734,
      "learning_rate": 5.062664907651715e-05,
      "loss": 2.3584,
      "step": 1500
    },
    {
      "epoch": 1.0,
      "eval_loss": 2.2437479496002197,
      "eval_runtime": 14.4779,
      "eval_samples_per_second": 23.277,
      "eval_steps_per_second": 5.871,
      "step": 1516
    },
    {
      "epoch": 1.3192612137203166,
      "grad_norm": 3.3703572750091553,
      "learning_rate": 3.413588390501319e-05,
      "loss": 1.9816,
      "step": 2000
    },
    {
      "epoch": 1.6490765171503958,
      "grad_norm": 6.067132949829102,
      "learning_rate": 1.7645118733509235e-05,
      "loss": 1.9557,
      "step": 2500
    },
    {
      "epoch": 1.978891820580475,
      "grad_norm": 5.649411678314209,
      "learning_rate": 1.154353562005277e-06,
      "loss": 1.8931,
      "step": 3000
    },
    {
      "epoch": 2.308707124010554,
      "grad_norm": 7.094686508178711,
      "learning_rate": 9.077572559366754e-05,
      "loss": 1.708,
      "step": 3500
    },
    {
      "epoch": 2.638522427440633,
      "grad_norm": 9.227572441101074,
      "learning_rate": 8.945910290237468e-05,
      "loss": 1.7662,
      "step": 4000
    },
    {
      "epoch": 2.9683377308707124,
      "grad_norm": 7.1667609214782715,
      "learning_rate": 8.813984168865435e-05,
      "loss": 1.8414,
      "step": 4500
    },
    {
      "epoch": 3.0,
      "eval_loss": 2.4012889862060547,
      "eval_runtime": 14.6125,
      "eval_samples_per_second": 23.062,
      "eval_steps_per_second": 5.817,
      "step": 4548
    },
    {
      "epoch": 3.2981530343007917,
      "grad_norm": 14.503642082214355,
      "learning_rate": 8.682058047493404e-05,
      "loss": 1.1945,
      "step": 5000
    },
    {
      "epoch": 3.627968337730871,
      "grad_norm": 5.12998104095459,
      "learning_rate": 8.550131926121372e-05,
      "loss": 1.2169,
      "step": 5500
    },
    {
      "epoch": 3.9577836411609497,
      "grad_norm": 5.000731468200684,
      "learning_rate": 8.418733509234829e-05,
      "loss": 1.2238,
      "step": 6000
    },
    {
      "epoch": 4.0,
      "eval_loss": 2.7897167205810547,
      "eval_runtime": 14.4821,
      "eval_samples_per_second": 23.27,
      "eval_steps_per_second": 5.869,
      "step": 6064
    },
    {
      "epoch": 4.287598944591029,
      "grad_norm": 11.568550109863281,
      "learning_rate": 8.286807387862797e-05,
      "loss": 0.7359,
      "step": 6500
    },
    {
      "epoch": 4.617414248021108,
      "grad_norm": 10.648757934570312,
      "learning_rate": 8.154881266490766e-05,
      "loss": 0.6891,
      "step": 7000
    },
    {
      "epoch": 4.947229551451187,
      "grad_norm": 9.68858528137207,
      "learning_rate": 8.022955145118733e-05,
      "loss": 0.72,
      "step": 7500
    },
    {
      "epoch": 5.0,
      "eval_loss": 3.2005105018615723,
      "eval_runtime": 14.4951,
      "eval_samples_per_second": 23.249,
      "eval_steps_per_second": 5.864,
      "step": 7580
    },
    {
      "epoch": 5.277044854881266,
      "grad_norm": 8.410784721374512,
      "learning_rate": 7.891029023746702e-05,
      "loss": 0.4068,
      "step": 8000
    },
    {
      "epoch": 5.6068601583113455,
      "grad_norm": 7.6726155281066895,
      "learning_rate": 7.759102902374671e-05,
      "loss": 0.3935,
      "step": 8500
    },
    {
      "epoch": 5.936675461741425,
      "grad_norm": 10.912120819091797,
      "learning_rate": 7.627176781002639e-05,
      "loss": 0.4195,
      "step": 9000
    },
    {
      "epoch": 6.0,
      "eval_loss": 3.631282329559326,
      "eval_runtime": 14.4762,
      "eval_samples_per_second": 23.28,
      "eval_steps_per_second": 5.872,
      "step": 9096
    },
    {
      "epoch": 6.266490765171504,
      "grad_norm": 3.1752233505249023,
      "learning_rate": 7.495250659630607e-05,
      "loss": 0.2571,
      "step": 9500
    },
    {
      "epoch": 6.596306068601583,
      "grad_norm": 3.35020112991333,
      "learning_rate": 7.36358839050132e-05,
      "loss": 0.2558,
      "step": 10000
    },
    {
      "epoch": 6.926121372031663,
      "grad_norm": 9.565552711486816,
      "learning_rate": 7.231662269129287e-05,
      "loss": 0.2814,
      "step": 10500
    },
    {
      "epoch": 7.0,
      "eval_loss": 3.8077571392059326,
      "eval_runtime": 14.3713,
      "eval_samples_per_second": 23.45,
      "eval_steps_per_second": 5.915,
      "step": 10612
    },
    {
      "epoch": 7.255936675461742,
      "grad_norm": 8.368778228759766,
      "learning_rate": 7.099736147757256e-05,
      "loss": 0.1921,
      "step": 11000
    },
    {
      "epoch": 7.585751978891821,
      "grad_norm": 3.944981098175049,
      "learning_rate": 6.967810026385224e-05,
      "loss": 0.1862,
      "step": 11500
    },
    {
      "epoch": 7.915567282321899,
      "grad_norm": 5.475448131561279,
      "learning_rate": 6.836147757255937e-05,
      "loss": 0.2134,
      "step": 12000
    },
    {
      "epoch": 8.0,
      "eval_loss": 4.112706661224365,
      "eval_runtime": 14.3703,
      "eval_samples_per_second": 23.451,
      "eval_steps_per_second": 5.915,
      "step": 12128
    },
    {
      "epoch": 8.24538258575198,
      "grad_norm": 6.960862636566162,
      "learning_rate": 6.704221635883905e-05,
      "loss": 0.1499,
      "step": 12500
    },
    {
      "epoch": 8.575197889182059,
      "grad_norm": 7.1337666511535645,
      "learning_rate": 6.572295514511874e-05,
      "loss": 0.1487,
      "step": 13000
    },
    {
      "epoch": 8.905013192612138,
      "grad_norm": 8.323104858398438,
      "learning_rate": 6.440369393139843e-05,
      "loss": 0.1704,
      "step": 13500
    },
    {
      "epoch": 9.0,
      "eval_loss": 4.308851718902588,
      "eval_runtime": 14.3668,
      "eval_samples_per_second": 23.457,
      "eval_steps_per_second": 5.916,
      "step": 13644
    },
    {
      "epoch": 9.234828496042216,
      "grad_norm": 3.419377326965332,
      "learning_rate": 6.308707124010554e-05,
      "loss": 0.1381,
      "step": 14000
    },
    {
      "epoch": 9.564643799472295,
      "grad_norm": 5.7849345207214355,
      "learning_rate": 6.176781002638523e-05,
      "loss": 0.1343,
      "step": 14500
    },
    {
      "epoch": 9.894459102902374,
      "grad_norm": 2.064253568649292,
      "learning_rate": 6.0448548812664904e-05,
      "loss": 0.1373,
      "step": 15000
    },
    {
      "epoch": 10.0,
      "eval_loss": 4.510509014129639,
      "eval_runtime": 14.361,
      "eval_samples_per_second": 23.466,
      "eval_steps_per_second": 5.919,
      "step": 15160
    },
    {
      "epoch": 10.224274406332453,
      "grad_norm": 0.9780070185661316,
      "learning_rate": 5.9129287598944594e-05,
      "loss": 0.1158,
      "step": 15500
    },
    {
      "epoch": 10.554089709762533,
      "grad_norm": 1.335127830505371,
      "learning_rate": 5.7810026385224284e-05,
      "loss": 0.1178,
      "step": 16000
    },
    {
      "epoch": 10.883905013192612,
      "grad_norm": 1.0371098518371582,
      "learning_rate": 5.64934036939314e-05,
      "loss": 0.127,
      "step": 16500
    },
    {
      "epoch": 11.0,
      "eval_loss": 4.654536724090576,
      "eval_runtime": 14.3609,
      "eval_samples_per_second": 23.466,
      "eval_steps_per_second": 5.919,
      "step": 16676
    },
    {
      "epoch": 11.213720316622691,
      "grad_norm": 1.7252776622772217,
      "learning_rate": 5.517414248021109e-05,
      "loss": 0.1095,
      "step": 17000
    },
    {
      "epoch": 11.54353562005277,
      "grad_norm": 1.6535075902938843,
      "learning_rate": 5.385488126649076e-05,
      "loss": 0.1001,
      "step": 17500
    },
    {
      "epoch": 11.87335092348285,
      "grad_norm": 1.9925291538238525,
      "learning_rate": 5.253562005277045e-05,
      "loss": 0.1096,
      "step": 18000
    },
    {
      "epoch": 12.0,
      "eval_loss": 4.821412086486816,
      "eval_runtime": 14.3735,
      "eval_samples_per_second": 23.446,
      "eval_steps_per_second": 5.914,
      "step": 18192
    },
    {
      "epoch": 12.203166226912929,
      "grad_norm": 1.8665218353271484,
      "learning_rate": 5.121899736147757e-05,
      "loss": 0.0946,
      "step": 18500
    },
    {
      "epoch": 12.532981530343008,
      "grad_norm": 6.382734298706055,
      "learning_rate": 4.989973614775726e-05,
      "loss": 0.0919,
      "step": 19000
    },
    {
      "epoch": 12.862796833773087,
      "grad_norm": 0.799485445022583,
      "learning_rate": 4.858047493403694e-05,
      "loss": 0.0998,
      "step": 19500
    },
    {
      "epoch": 13.0,
      "eval_loss": 4.969611644744873,
      "eval_runtime": 14.4727,
      "eval_samples_per_second": 23.285,
      "eval_steps_per_second": 5.873,
      "step": 19708
    },
    {
      "epoch": 13.192612137203167,
      "grad_norm": 8.104708671569824,
      "learning_rate": 4.7261213720316625e-05,
      "loss": 0.0809,
      "step": 20000
    },
    {
      "epoch": 13.522427440633246,
      "grad_norm": 0.5777403116226196,
      "learning_rate": 4.594195250659631e-05,
      "loss": 0.0829,
      "step": 20500
    },
    {
      "epoch": 13.852242744063325,
      "grad_norm": 2.662170648574829,
      "learning_rate": 4.462269129287599e-05,
      "loss": 0.0881,
      "step": 21000
    },
    {
      "epoch": 14.0,
      "eval_loss": 5.08657169342041,
      "eval_runtime": 14.4604,
      "eval_samples_per_second": 23.305,
      "eval_steps_per_second": 5.878,
      "step": 21224
    },
    {
      "epoch": 14.182058047493404,
      "grad_norm": 1.5740467309951782,
      "learning_rate": 4.3303430079155674e-05,
      "loss": 0.0759,
      "step": 21500
    },
    {
      "epoch": 14.511873350923484,
      "grad_norm": 1.722854733467102,
      "learning_rate": 4.198416886543536e-05,
      "loss": 0.0741,
      "step": 22000
    },
    {
      "epoch": 14.841688654353561,
      "grad_norm": 1.6402174234390259,
      "learning_rate": 4.066754617414248e-05,
      "loss": 0.0839,
      "step": 22500
    },
    {
      "epoch": 15.0,
      "eval_loss": 5.358933448791504,
      "eval_runtime": 14.4669,
      "eval_samples_per_second": 23.294,
      "eval_steps_per_second": 5.875,
      "step": 22740
    },
    {
      "epoch": 15.17150395778364,
      "grad_norm": 1.054844617843628,
      "learning_rate": 3.9348284960422165e-05,
      "loss": 0.0707,
      "step": 23000
    },
    {
      "epoch": 15.50131926121372,
      "grad_norm": 0.6180419921875,
      "learning_rate": 3.802902374670185e-05,
      "loss": 0.0674,
      "step": 23500
    },
    {
      "epoch": 15.831134564643799,
      "grad_norm": 0.5451957583427429,
      "learning_rate": 3.670976253298153e-05,
      "loss": 0.075,
      "step": 24000
    },
    {
      "epoch": 16.0,
      "eval_loss": 5.393375873565674,
      "eval_runtime": 14.4498,
      "eval_samples_per_second": 23.322,
      "eval_steps_per_second": 5.882,
      "step": 24256
    },
    {
      "epoch": 16.160949868073878,
      "grad_norm": 2.360567808151245,
      "learning_rate": 3.5390501319261214e-05,
      "loss": 0.0689,
      "step": 24500
    },
    {
      "epoch": 16.49076517150396,
      "grad_norm": 1.22458815574646,
      "learning_rate": 3.40712401055409e-05,
      "loss": 0.0631,
      "step": 25000
    },
    {
      "epoch": 16.820580474934037,
      "grad_norm": 1.0296965837478638,
      "learning_rate": 3.275461741424802e-05,
      "loss": 0.0753,
      "step": 25500
    },
    {
      "epoch": 17.0,
      "eval_loss": 5.527252674102783,
      "eval_runtime": 14.4728,
      "eval_samples_per_second": 23.285,
      "eval_steps_per_second": 5.873,
      "step": 25772
    },
    {
      "epoch": 17.150395778364118,
      "grad_norm": 1.3442260026931763,
      "learning_rate": 3.1435356200527705e-05,
      "loss": 0.0609,
      "step": 26000
    },
    {
      "epoch": 17.480211081794195,
      "grad_norm": 0.6123533844947815,
      "learning_rate": 3.011609498680739e-05,
      "loss": 0.0608,
      "step": 26500
    },
    {
      "epoch": 17.810026385224276,
      "grad_norm": 1.0486321449279785,
      "learning_rate": 2.879683377308707e-05,
      "loss": 0.0645,
      "step": 27000
    },
    {
      "epoch": 18.0,
      "eval_loss": 5.578597545623779,
      "eval_runtime": 14.47,
      "eval_samples_per_second": 23.29,
      "eval_steps_per_second": 5.874,
      "step": 27288
    },
    {
      "epoch": 18.139841688654354,
      "grad_norm": 1.171905755996704,
      "learning_rate": 2.7477572559366754e-05,
      "loss": 0.0618,
      "step": 27500
    },
    {
      "epoch": 18.46965699208443,
      "grad_norm": 0.5490497946739197,
      "learning_rate": 2.615831134564644e-05,
      "loss": 0.0582,
      "step": 28000
    },
    {
      "epoch": 18.799472295514512,
      "grad_norm": 0.7064627408981323,
      "learning_rate": 2.4839050131926124e-05,
      "loss": 0.0601,
      "step": 28500
    },
    {
      "epoch": 19.0,
      "eval_loss": 5.673792839050293,
      "eval_runtime": 14.4949,
      "eval_samples_per_second": 23.25,
      "eval_steps_per_second": 5.864,
      "step": 28804
    },
    {
      "epoch": 19.12928759894459,
      "grad_norm": 1.3784384727478027,
      "learning_rate": 2.3519788918205807e-05,
      "loss": 0.0578,
      "step": 29000
    },
    {
      "epoch": 19.45910290237467,
      "grad_norm": 0.8921707272529602,
      "learning_rate": 2.2200527704485487e-05,
      "loss": 0.0525,
      "step": 29500
    },
    {
      "epoch": 19.788918205804748,
      "grad_norm": 0.2738703489303589,
      "learning_rate": 2.0881266490765174e-05,
      "loss": 0.0574,
      "step": 30000
    },
    {
      "epoch": 20.0,
      "eval_loss": 5.908054351806641,
      "eval_runtime": 14.5091,
      "eval_samples_per_second": 23.227,
      "eval_steps_per_second": 5.858,
      "step": 30320
    },
    {
      "epoch": 20.11873350923483,
      "grad_norm": 0.7793926000595093,
      "learning_rate": 1.9564643799472295e-05,
      "loss": 0.0548,
      "step": 30500
    },
    {
      "epoch": 20.448548812664907,
      "grad_norm": 1.0103569030761719,
      "learning_rate": 1.824538258575198e-05,
      "loss": 0.0478,
      "step": 31000
    },
    {
      "epoch": 20.778364116094988,
      "grad_norm": 0.8269590139389038,
      "learning_rate": 1.6926121372031664e-05,
      "loss": 0.0547,
      "step": 31500
    },
    {
      "epoch": 21.0,
      "eval_loss": 5.897144794464111,
      "eval_runtime": 14.4219,
      "eval_samples_per_second": 23.367,
      "eval_steps_per_second": 5.894,
      "step": 31836
    },
    {
      "epoch": 21.108179419525065,
      "grad_norm": 0.5495963096618652,
      "learning_rate": 1.5606860158311344e-05,
      "loss": 0.0526,
      "step": 32000
    },
    {
      "epoch": 21.437994722955146,
      "grad_norm": 1.9158118963241577,
      "learning_rate": 1.4287598944591029e-05,
      "loss": 0.0447,
      "step": 32500
    },
    {
      "epoch": 21.767810026385224,
      "grad_norm": 0.8156965970993042,
      "learning_rate": 1.2970976253298153e-05,
      "loss": 0.0525,
      "step": 33000
    },
    {
      "epoch": 22.0,
      "eval_loss": 5.960947036743164,
      "eval_runtime": 14.4289,
      "eval_samples_per_second": 23.356,
      "eval_steps_per_second": 5.891,
      "step": 33352
    },
    {
      "epoch": 22.097625329815305,
      "grad_norm": 0.6796886920928955,
      "learning_rate": 1.1651715039577838e-05,
      "loss": 0.0497,
      "step": 33500
    },
    {
      "epoch": 22.427440633245382,
      "grad_norm": 0.8412973880767822,
      "learning_rate": 1.033245382585752e-05,
      "loss": 0.0431,
      "step": 34000
    },
    {
      "epoch": 22.757255936675463,
      "grad_norm": 0.6374260187149048,
      "learning_rate": 9.013192612137204e-06,
      "loss": 0.0471,
      "step": 34500
    },
    {
      "epoch": 23.0,
      "eval_loss": 5.984443664550781,
      "eval_runtime": 14.3844,
      "eval_samples_per_second": 23.428,
      "eval_steps_per_second": 5.909,
      "step": 34868
    },
    {
      "epoch": 23.08707124010554,
      "grad_norm": 0.9351519346237183,
      "learning_rate": 7.693931398416887e-06,
      "loss": 0.0471,
      "step": 35000
    },
    {
      "epoch": 23.41688654353562,
      "grad_norm": 0.9671851992607117,
      "learning_rate": 6.37467018469657e-06,
      "loss": 0.0411,
      "step": 35500
    },
    {
      "epoch": 23.7467018469657,
      "grad_norm": 0.7803508043289185,
      "learning_rate": 5.055408970976253e-06,
      "loss": 0.0442,
      "step": 36000
    },
    {
      "epoch": 24.0,
      "eval_loss": 6.121158599853516,
      "eval_runtime": 14.41,
      "eval_samples_per_second": 23.387,
      "eval_steps_per_second": 5.899,
      "step": 36384
    },
    {
      "epoch": 24.076517150395777,
      "grad_norm": 0.8351489305496216,
      "learning_rate": 3.7361477572559365e-06,
      "loss": 0.0439,
      "step": 36500
    },
    {
      "epoch": 24.406332453825858,
      "grad_norm": 0.42780637741088867,
      "learning_rate": 2.419525065963061e-06,
      "loss": 0.0393,
      "step": 37000
    },
    {
      "epoch": 24.736147757255935,
      "grad_norm": 0.8055735230445862,
      "learning_rate": 1.100263852242744e-06,
      "loss": 0.0384,
      "step": 37500
    },
    {
      "epoch": 25.0,
      "eval_loss": 6.230334281921387,
      "eval_runtime": 14.4173,
      "eval_samples_per_second": 23.375,
      "eval_steps_per_second": 5.896,
      "step": 37900
    },
    {
      "epoch": 25.0,
      "step": 37900,
      "total_flos": 3.064554823318733e+17,
      "train_loss": 0.23232732641980014,
      "train_runtime": 10116.7774,
      "train_samples_per_second": 7.493,
      "train_steps_per_second": 3.746
    }
  ],
  "logging_steps": 500,
  "max_steps": 37900,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 25,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.064554823318733e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}

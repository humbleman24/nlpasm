{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 20.0,
  "eval_steps": 500,
  "global_step": 30360,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.32938076416337286,
      "grad_norm": 8.436219215393066,
      "learning_rate": 6.725955204216075e-05,
      "loss": 2.1807,
      "step": 500
    },
    {
      "epoch": 0.6587615283267457,
      "grad_norm": 5.642808437347412,
      "learning_rate": 3.4321475625823454e-05,
      "loss": 2.1242,
      "step": 1000
    },
    {
      "epoch": 0.9881422924901185,
      "grad_norm": 3.852980375289917,
      "learning_rate": 1.3833992094861662e-06,
      "loss": 2.0146,
      "step": 1500
    },
    {
      "epoch": 1.3175230566534915,
      "grad_norm": 9.660499572753906,
      "learning_rate": 9.342885375494071e-05,
      "loss": 1.7738,
      "step": 2000
    },
    {
      "epoch": 1.6469038208168643,
      "grad_norm": 5.154603004455566,
      "learning_rate": 9.178194993412386e-05,
      "loss": 1.8285,
      "step": 2500
    },
    {
      "epoch": 1.9762845849802373,
      "grad_norm": 2.924184560775757,
      "learning_rate": 9.013833992094862e-05,
      "loss": 1.8398,
      "step": 3000
    },
    {
      "epoch": 2.0,
      "eval_loss": 2.018383741378784,
      "eval_runtime": 13.0472,
      "eval_samples_per_second": 25.906,
      "eval_steps_per_second": 6.515,
      "step": 3036
    },
    {
      "epoch": 2.30566534914361,
      "grad_norm": 3.7518417835235596,
      "learning_rate": 8.849143610013176e-05,
      "loss": 1.2933,
      "step": 3500
    },
    {
      "epoch": 2.635046113306983,
      "grad_norm": 5.83681058883667,
      "learning_rate": 8.68445322793149e-05,
      "loss": 1.2504,
      "step": 4000
    },
    {
      "epoch": 2.9644268774703555,
      "grad_norm": 6.916069507598877,
      "learning_rate": 8.519762845849803e-05,
      "loss": 1.2733,
      "step": 4500
    },
    {
      "epoch": 3.0,
      "eval_loss": 2.178071975708008,
      "eval_runtime": 12.9868,
      "eval_samples_per_second": 26.026,
      "eval_steps_per_second": 6.545,
      "step": 4554
    },
    {
      "epoch": 3.2938076416337285,
      "grad_norm": 7.715989589691162,
      "learning_rate": 8.35540184453228e-05,
      "loss": 0.7846,
      "step": 5000
    },
    {
      "epoch": 3.6231884057971016,
      "grad_norm": 4.797492027282715,
      "learning_rate": 8.190711462450593e-05,
      "loss": 0.7582,
      "step": 5500
    },
    {
      "epoch": 3.9525691699604746,
      "grad_norm": 9.308773040771484,
      "learning_rate": 8.026021080368907e-05,
      "loss": 0.7796,
      "step": 6000
    },
    {
      "epoch": 4.0,
      "eval_loss": 2.4889893531799316,
      "eval_runtime": 13.051,
      "eval_samples_per_second": 25.898,
      "eval_steps_per_second": 6.513,
      "step": 6072
    },
    {
      "epoch": 4.281949934123848,
      "grad_norm": 6.495525360107422,
      "learning_rate": 7.86133069828722e-05,
      "loss": 0.4392,
      "step": 6500
    },
    {
      "epoch": 4.61133069828722,
      "grad_norm": 16.337257385253906,
      "learning_rate": 7.696969696969696e-05,
      "loss": 0.402,
      "step": 7000
    },
    {
      "epoch": 4.940711462450593,
      "grad_norm": 6.270818710327148,
      "learning_rate": 7.53227931488801e-05,
      "loss": 0.4491,
      "step": 7500
    },
    {
      "epoch": 5.0,
      "eval_loss": 2.6964573860168457,
      "eval_runtime": 13.0903,
      "eval_samples_per_second": 25.821,
      "eval_steps_per_second": 6.493,
      "step": 7590
    },
    {
      "epoch": 5.270092226613966,
      "grad_norm": 2.857581615447998,
      "learning_rate": 7.367588932806325e-05,
      "loss": 0.2633,
      "step": 8000
    },
    {
      "epoch": 5.599472990777339,
      "grad_norm": 7.286682605743408,
      "learning_rate": 7.202898550724639e-05,
      "loss": 0.2421,
      "step": 8500
    },
    {
      "epoch": 5.928853754940711,
      "grad_norm": 8.666751861572266,
      "learning_rate": 7.038208168642952e-05,
      "loss": 0.2618,
      "step": 9000
    },
    {
      "epoch": 6.0,
      "eval_loss": 3.046846389770508,
      "eval_runtime": 13.0654,
      "eval_samples_per_second": 25.87,
      "eval_steps_per_second": 6.506,
      "step": 9108
    },
    {
      "epoch": 6.258234519104084,
      "grad_norm": 3.272231340408325,
      "learning_rate": 6.873847167325429e-05,
      "loss": 0.1695,
      "step": 9500
    },
    {
      "epoch": 6.587615283267457,
      "grad_norm": 3.9738314151763916,
      "learning_rate": 6.709156785243742e-05,
      "loss": 0.1753,
      "step": 10000
    },
    {
      "epoch": 6.91699604743083,
      "grad_norm": 8.787158012390137,
      "learning_rate": 6.544466403162056e-05,
      "loss": 0.1826,
      "step": 10500
    },
    {
      "epoch": 7.0,
      "eval_loss": 3.184704542160034,
      "eval_runtime": 12.9691,
      "eval_samples_per_second": 26.062,
      "eval_steps_per_second": 6.554,
      "step": 10626
    },
    {
      "epoch": 7.246376811594203,
      "grad_norm": 5.9161553382873535,
      "learning_rate": 6.379776021080369e-05,
      "loss": 0.1376,
      "step": 11000
    },
    {
      "epoch": 7.575757575757576,
      "grad_norm": 3.561976909637451,
      "learning_rate": 6.215085638998682e-05,
      "loss": 0.1328,
      "step": 11500
    },
    {
      "epoch": 7.905138339920948,
      "grad_norm": 3.3604795932769775,
      "learning_rate": 6.05072463768116e-05,
      "loss": 0.1459,
      "step": 12000
    },
    {
      "epoch": 8.0,
      "eval_loss": 3.3976993560791016,
      "eval_runtime": 13.0112,
      "eval_samples_per_second": 25.978,
      "eval_steps_per_second": 6.533,
      "step": 12144
    },
    {
      "epoch": 8.234519104084322,
      "grad_norm": 1.8270219564437866,
      "learning_rate": 5.886034255599473e-05,
      "loss": 0.1117,
      "step": 12500
    },
    {
      "epoch": 8.563899868247695,
      "grad_norm": 2.832308292388916,
      "learning_rate": 5.721343873517787e-05,
      "loss": 0.1082,
      "step": 13000
    },
    {
      "epoch": 8.893280632411066,
      "grad_norm": 5.856059551239014,
      "learning_rate": 5.5566534914361005e-05,
      "loss": 0.1213,
      "step": 13500
    },
    {
      "epoch": 9.0,
      "eval_loss": 3.4801857471466064,
      "eval_runtime": 12.9706,
      "eval_samples_per_second": 26.059,
      "eval_steps_per_second": 6.553,
      "step": 13662
    },
    {
      "epoch": 9.22266139657444,
      "grad_norm": 4.107310771942139,
      "learning_rate": 5.3919631093544146e-05,
      "loss": 0.1024,
      "step": 14000
    },
    {
      "epoch": 9.552042160737813,
      "grad_norm": 1.9205790758132935,
      "learning_rate": 5.2272727272727274e-05,
      "loss": 0.0963,
      "step": 14500
    },
    {
      "epoch": 9.881422924901186,
      "grad_norm": 2.262683629989624,
      "learning_rate": 5.0625823451910416e-05,
      "loss": 0.0998,
      "step": 15000
    },
    {
      "epoch": 10.0,
      "eval_loss": 3.6420984268188477,
      "eval_runtime": 13.1527,
      "eval_samples_per_second": 25.698,
      "eval_steps_per_second": 6.463,
      "step": 15180
    },
    {
      "epoch": 10.210803689064559,
      "grad_norm": 0.9399715065956116,
      "learning_rate": 4.8978919631093544e-05,
      "loss": 0.0833,
      "step": 15500
    },
    {
      "epoch": 10.540184453227932,
      "grad_norm": 1.3027575016021729,
      "learning_rate": 4.733530961791832e-05,
      "loss": 0.0822,
      "step": 16000
    },
    {
      "epoch": 10.869565217391305,
      "grad_norm": 1.0499045848846436,
      "learning_rate": 4.5688405797101454e-05,
      "loss": 0.0887,
      "step": 16500
    },
    {
      "epoch": 11.0,
      "eval_loss": 3.7952311038970947,
      "eval_runtime": 12.9998,
      "eval_samples_per_second": 26.0,
      "eval_steps_per_second": 6.539,
      "step": 16698
    },
    {
      "epoch": 11.198945981554678,
      "grad_norm": 1.1024432182312012,
      "learning_rate": 4.404150197628459e-05,
      "loss": 0.0709,
      "step": 17000
    },
    {
      "epoch": 11.52832674571805,
      "grad_norm": 0.6462278962135315,
      "learning_rate": 4.240118577075099e-05,
      "loss": 0.0701,
      "step": 17500
    },
    {
      "epoch": 11.857707509881424,
      "grad_norm": 0.5210846662521362,
      "learning_rate": 4.075428194993413e-05,
      "loss": 0.0761,
      "step": 18000
    },
    {
      "epoch": 12.0,
      "eval_loss": 3.8100168704986572,
      "eval_runtime": 13.3084,
      "eval_samples_per_second": 25.398,
      "eval_steps_per_second": 6.387,
      "step": 18216
    },
    {
      "epoch": 12.187088274044795,
      "grad_norm": 0.5883873105049133,
      "learning_rate": 3.910737812911726e-05,
      "loss": 0.0629,
      "step": 18500
    },
    {
      "epoch": 12.516469038208168,
      "grad_norm": 0.7963922023773193,
      "learning_rate": 3.7460474308300396e-05,
      "loss": 0.0635,
      "step": 19000
    },
    {
      "epoch": 12.845849802371541,
      "grad_norm": 0.667178750038147,
      "learning_rate": 3.581686429512517e-05,
      "loss": 0.0666,
      "step": 19500
    },
    {
      "epoch": 13.0,
      "eval_loss": 4.0090651512146,
      "eval_runtime": 13.0956,
      "eval_samples_per_second": 25.81,
      "eval_steps_per_second": 6.491,
      "step": 19734
    },
    {
      "epoch": 13.175230566534914,
      "grad_norm": 0.6670734882354736,
      "learning_rate": 3.416996047430831e-05,
      "loss": 0.0569,
      "step": 20000
    },
    {
      "epoch": 13.504611330698287,
      "grad_norm": 0.5719125270843506,
      "learning_rate": 3.2523056653491435e-05,
      "loss": 0.0538,
      "step": 20500
    },
    {
      "epoch": 13.83399209486166,
      "grad_norm": 0.4359646141529083,
      "learning_rate": 3.087615283267457e-05,
      "loss": 0.0623,
      "step": 21000
    },
    {
      "epoch": 14.0,
      "eval_loss": 4.122016429901123,
      "eval_runtime": 13.0969,
      "eval_samples_per_second": 25.808,
      "eval_steps_per_second": 6.49,
      "step": 21252
    },
    {
      "epoch": 14.163372859025033,
      "grad_norm": 0.4290478825569153,
      "learning_rate": 2.9229249011857708e-05,
      "loss": 0.0515,
      "step": 21500
    },
    {
      "epoch": 14.492753623188406,
      "grad_norm": 0.47144538164138794,
      "learning_rate": 2.7585638998682476e-05,
      "loss": 0.0487,
      "step": 22000
    },
    {
      "epoch": 14.82213438735178,
      "grad_norm": 0.5143328309059143,
      "learning_rate": 2.5938735177865615e-05,
      "loss": 0.054,
      "step": 22500
    },
    {
      "epoch": 15.0,
      "eval_loss": 4.180332183837891,
      "eval_runtime": 13.1142,
      "eval_samples_per_second": 25.773,
      "eval_steps_per_second": 6.482,
      "step": 22770
    },
    {
      "epoch": 15.151515151515152,
      "grad_norm": 0.4141641855239868,
      "learning_rate": 2.429183135704875e-05,
      "loss": 0.0501,
      "step": 23000
    },
    {
      "epoch": 15.480895915678524,
      "grad_norm": 0.4011829197406769,
      "learning_rate": 2.2644927536231884e-05,
      "loss": 0.0453,
      "step": 23500
    },
    {
      "epoch": 15.810276679841897,
      "grad_norm": 0.6064033508300781,
      "learning_rate": 2.0998023715415023e-05,
      "loss": 0.0495,
      "step": 24000
    },
    {
      "epoch": 16.0,
      "eval_loss": 4.255992412567139,
      "eval_runtime": 13.1145,
      "eval_samples_per_second": 25.773,
      "eval_steps_per_second": 6.481,
      "step": 24288
    },
    {
      "epoch": 16.13965744400527,
      "grad_norm": 0.33159875869750977,
      "learning_rate": 1.9351119894598157e-05,
      "loss": 0.0457,
      "step": 24500
    },
    {
      "epoch": 16.469038208168644,
      "grad_norm": 0.6371428966522217,
      "learning_rate": 1.7704216073781292e-05,
      "loss": 0.0414,
      "step": 25000
    },
    {
      "epoch": 16.798418972332016,
      "grad_norm": 0.7707323431968689,
      "learning_rate": 1.6057312252964427e-05,
      "loss": 0.044,
      "step": 25500
    },
    {
      "epoch": 17.0,
      "eval_loss": 4.31951904296875,
      "eval_runtime": 13.1265,
      "eval_samples_per_second": 25.75,
      "eval_steps_per_second": 6.475,
      "step": 25806
    },
    {
      "epoch": 17.12779973649539,
      "grad_norm": 0.38088539242744446,
      "learning_rate": 1.4410408432147562e-05,
      "loss": 0.0411,
      "step": 26000
    },
    {
      "epoch": 17.45718050065876,
      "grad_norm": 0.5271909832954407,
      "learning_rate": 1.2766798418972334e-05,
      "loss": 0.0364,
      "step": 26500
    },
    {
      "epoch": 17.786561264822133,
      "grad_norm": 0.2761726677417755,
      "learning_rate": 1.1119894598155469e-05,
      "loss": 0.0407,
      "step": 27000
    },
    {
      "epoch": 18.0,
      "eval_loss": 4.392557144165039,
      "eval_runtime": 13.0262,
      "eval_samples_per_second": 25.948,
      "eval_steps_per_second": 6.525,
      "step": 27324
    },
    {
      "epoch": 18.115942028985508,
      "grad_norm": 0.4729611277580261,
      "learning_rate": 9.472990777338604e-06,
      "loss": 0.0396,
      "step": 27500
    },
    {
      "epoch": 18.44532279314888,
      "grad_norm": 0.3166634142398834,
      "learning_rate": 7.82608695652174e-06,
      "loss": 0.0333,
      "step": 28000
    },
    {
      "epoch": 18.774703557312254,
      "grad_norm": 0.5119631886482239,
      "learning_rate": 6.182476943346509e-06,
      "loss": 0.0371,
      "step": 28500
    },
    {
      "epoch": 19.0,
      "eval_loss": 4.447565078735352,
      "eval_runtime": 13.0722,
      "eval_samples_per_second": 25.856,
      "eval_steps_per_second": 6.502,
      "step": 28842
    },
    {
      "epoch": 19.104084321475625,
      "grad_norm": 0.42438259720802307,
      "learning_rate": 4.5355731225296446e-06,
      "loss": 0.0357,
      "step": 29000
    },
    {
      "epoch": 19.433465085639,
      "grad_norm": 0.5486689805984497,
      "learning_rate": 2.8919631093544137e-06,
      "loss": 0.0313,
      "step": 29500
    },
    {
      "epoch": 19.76284584980237,
      "grad_norm": 0.988335371017456,
      "learning_rate": 1.2450592885375494e-06,
      "loss": 0.0317,
      "step": 30000
    },
    {
      "epoch": 20.0,
      "eval_loss": 4.573833465576172,
      "eval_runtime": 13.0929,
      "eval_samples_per_second": 25.816,
      "eval_steps_per_second": 6.492,
      "step": 30360
    },
    {
      "epoch": 20.0,
      "step": 30360,
      "total_flos": 2.543064142876508e+17,
      "train_loss": 0.021288126887697163,
      "train_runtime": 4310.0793,
      "train_samples_per_second": 14.088,
      "train_steps_per_second": 7.044
    }
  ],
  "logging_steps": 500,
  "max_steps": 30360,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 20,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.543064142876508e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}

{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 20.0,
  "eval_steps": 500,
  "global_step": 30300,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.33003300330033003,
      "grad_norm": 3.6295547485351562,
      "learning_rate": 6.712871287128713e-05,
      "loss": 2.207,
      "step": 500
    },
    {
      "epoch": 0.6600660066006601,
      "grad_norm": 3.3653616905212402,
      "learning_rate": 3.4191419141914195e-05,
      "loss": 2.0794,
      "step": 1000
    },
    {
      "epoch": 0.9900990099009901,
      "grad_norm": 4.1485066413879395,
      "learning_rate": 1.1881188118811881e-06,
      "loss": 2.0072,
      "step": 1500
    },
    {
      "epoch": 1.3201320132013201,
      "grad_norm": 7.171627044677734,
      "learning_rate": 9.341584158415843e-05,
      "loss": 1.7822,
      "step": 2000
    },
    {
      "epoch": 1.6501650165016502,
      "grad_norm": 5.19422721862793,
      "learning_rate": 9.176567656765677e-05,
      "loss": 1.82,
      "step": 2500
    },
    {
      "epoch": 1.9801980198019802,
      "grad_norm": 4.678783893585205,
      "learning_rate": 9.011881188118813e-05,
      "loss": 1.8175,
      "step": 3000
    },
    {
      "epoch": 2.0,
      "eval_loss": 2.1060945987701416,
      "eval_runtime": 12.7056,
      "eval_samples_per_second": 26.524,
      "eval_steps_per_second": 6.69,
      "step": 3030
    },
    {
      "epoch": 2.31023102310231,
      "grad_norm": 6.316774845123291,
      "learning_rate": 8.846864686468648e-05,
      "loss": 1.2728,
      "step": 3500
    },
    {
      "epoch": 2.6402640264026402,
      "grad_norm": 4.718968868255615,
      "learning_rate": 8.681848184818481e-05,
      "loss": 1.2692,
      "step": 4000
    },
    {
      "epoch": 2.9702970297029703,
      "grad_norm": 5.247274875640869,
      "learning_rate": 8.517161716171618e-05,
      "loss": 1.263,
      "step": 4500
    },
    {
      "epoch": 3.0,
      "eval_loss": 2.287428617477417,
      "eval_runtime": 12.7045,
      "eval_samples_per_second": 26.526,
      "eval_steps_per_second": 6.691,
      "step": 4545
    },
    {
      "epoch": 3.3003300330033003,
      "grad_norm": 5.844444274902344,
      "learning_rate": 8.352145214521453e-05,
      "loss": 0.768,
      "step": 5000
    },
    {
      "epoch": 3.6303630363036303,
      "grad_norm": 6.750708103179932,
      "learning_rate": 8.187128712871287e-05,
      "loss": 0.7267,
      "step": 5500
    },
    {
      "epoch": 3.9603960396039604,
      "grad_norm": 11.317044258117676,
      "learning_rate": 8.022112211221123e-05,
      "loss": 0.7931,
      "step": 6000
    },
    {
      "epoch": 4.0,
      "eval_loss": 2.576547861099243,
      "eval_runtime": 12.7596,
      "eval_samples_per_second": 26.412,
      "eval_steps_per_second": 6.662,
      "step": 6060
    },
    {
      "epoch": 4.29042904290429,
      "grad_norm": 11.833318710327148,
      "learning_rate": 7.857095709570957e-05,
      "loss": 0.4295,
      "step": 6500
    },
    {
      "epoch": 4.62046204620462,
      "grad_norm": 4.0948028564453125,
      "learning_rate": 7.692079207920793e-05,
      "loss": 0.4103,
      "step": 7000
    },
    {
      "epoch": 4.9504950495049505,
      "grad_norm": 6.346575736999512,
      "learning_rate": 7.527062706270627e-05,
      "loss": 0.4393,
      "step": 7500
    },
    {
      "epoch": 5.0,
      "eval_loss": 2.906407117843628,
      "eval_runtime": 12.7034,
      "eval_samples_per_second": 26.528,
      "eval_steps_per_second": 6.691,
      "step": 7575
    },
    {
      "epoch": 5.2805280528052805,
      "grad_norm": 9.06006908416748,
      "learning_rate": 7.362046204620462e-05,
      "loss": 0.2467,
      "step": 8000
    },
    {
      "epoch": 5.6105610561056105,
      "grad_norm": 9.870311737060547,
      "learning_rate": 7.197359735973597e-05,
      "loss": 0.2422,
      "step": 8500
    },
    {
      "epoch": 5.9405940594059405,
      "grad_norm": 7.531358242034912,
      "learning_rate": 7.032343234323433e-05,
      "loss": 0.261,
      "step": 9000
    },
    {
      "epoch": 6.0,
      "eval_loss": 3.206836700439453,
      "eval_runtime": 12.6863,
      "eval_samples_per_second": 26.564,
      "eval_steps_per_second": 6.7,
      "step": 9090
    },
    {
      "epoch": 6.270627062706271,
      "grad_norm": 6.37757682800293,
      "learning_rate": 6.867326732673269e-05,
      "loss": 0.1744,
      "step": 9500
    },
    {
      "epoch": 6.600660066006601,
      "grad_norm": 7.16387939453125,
      "learning_rate": 6.702310231023102e-05,
      "loss": 0.1677,
      "step": 10000
    },
    {
      "epoch": 6.930693069306931,
      "grad_norm": 6.477144718170166,
      "learning_rate": 6.537623762376239e-05,
      "loss": 0.1824,
      "step": 10500
    },
    {
      "epoch": 7.0,
      "eval_loss": 3.359912395477295,
      "eval_runtime": 12.6955,
      "eval_samples_per_second": 26.545,
      "eval_steps_per_second": 6.695,
      "step": 10605
    },
    {
      "epoch": 7.260726072607261,
      "grad_norm": 2.031306266784668,
      "learning_rate": 6.372937293729373e-05,
      "loss": 0.134,
      "step": 11000
    },
    {
      "epoch": 7.590759075907591,
      "grad_norm": 2.9080047607421875,
      "learning_rate": 6.207920792079209e-05,
      "loss": 0.1258,
      "step": 11500
    },
    {
      "epoch": 7.920792079207921,
      "grad_norm": 1.2816137075424194,
      "learning_rate": 6.042904290429043e-05,
      "loss": 0.1418,
      "step": 12000
    },
    {
      "epoch": 8.0,
      "eval_loss": 3.460703134536743,
      "eval_runtime": 12.6951,
      "eval_samples_per_second": 26.546,
      "eval_steps_per_second": 6.695,
      "step": 12120
    },
    {
      "epoch": 8.250825082508252,
      "grad_norm": 1.2788994312286377,
      "learning_rate": 5.877887788778879e-05,
      "loss": 0.1094,
      "step": 12500
    },
    {
      "epoch": 8.58085808580858,
      "grad_norm": 6.276700973510742,
      "learning_rate": 5.7128712871287126e-05,
      "loss": 0.1051,
      "step": 13000
    },
    {
      "epoch": 8.910891089108912,
      "grad_norm": 3.330091714859009,
      "learning_rate": 5.548184818481849e-05,
      "loss": 0.1213,
      "step": 13500
    },
    {
      "epoch": 9.0,
      "eval_loss": 3.672379732131958,
      "eval_runtime": 12.7091,
      "eval_samples_per_second": 26.516,
      "eval_steps_per_second": 6.688,
      "step": 13635
    },
    {
      "epoch": 9.24092409240924,
      "grad_norm": 2.9989545345306396,
      "learning_rate": 5.383168316831684e-05,
      "loss": 0.0919,
      "step": 14000
    },
    {
      "epoch": 9.570957095709572,
      "grad_norm": 0.9558190107345581,
      "learning_rate": 5.2181518151815176e-05,
      "loss": 0.0968,
      "step": 14500
    },
    {
      "epoch": 9.900990099009901,
      "grad_norm": 4.069852352142334,
      "learning_rate": 5.0531353135313534e-05,
      "loss": 0.1011,
      "step": 15000
    },
    {
      "epoch": 10.0,
      "eval_loss": 3.712043285369873,
      "eval_runtime": 12.6979,
      "eval_samples_per_second": 26.54,
      "eval_steps_per_second": 6.694,
      "step": 15150
    },
    {
      "epoch": 10.231023102310232,
      "grad_norm": 1.2208341360092163,
      "learning_rate": 4.8881188118811884e-05,
      "loss": 0.0831,
      "step": 15500
    },
    {
      "epoch": 10.561056105610561,
      "grad_norm": 1.0894063711166382,
      "learning_rate": 4.7231023102310235e-05,
      "loss": 0.0813,
      "step": 16000
    },
    {
      "epoch": 10.891089108910892,
      "grad_norm": 1.6987240314483643,
      "learning_rate": 4.558085808580858e-05,
      "loss": 0.0933,
      "step": 16500
    },
    {
      "epoch": 11.0,
      "eval_loss": 3.77673602104187,
      "eval_runtime": 12.6912,
      "eval_samples_per_second": 26.554,
      "eval_steps_per_second": 6.698,
      "step": 16665
    },
    {
      "epoch": 11.221122112211221,
      "grad_norm": 1.3834619522094727,
      "learning_rate": 4.3930693069306936e-05,
      "loss": 0.071,
      "step": 17000
    },
    {
      "epoch": 11.551155115511552,
      "grad_norm": 2.157282590866089,
      "learning_rate": 4.228052805280529e-05,
      "loss": 0.0704,
      "step": 17500
    },
    {
      "epoch": 11.881188118811881,
      "grad_norm": 1.4262423515319824,
      "learning_rate": 4.063036303630363e-05,
      "loss": 0.0773,
      "step": 18000
    },
    {
      "epoch": 12.0,
      "eval_loss": 4.021827697753906,
      "eval_runtime": 12.812,
      "eval_samples_per_second": 26.303,
      "eval_steps_per_second": 6.634,
      "step": 18180
    },
    {
      "epoch": 12.211221122112212,
      "grad_norm": 0.38974395394325256,
      "learning_rate": 3.898349834983499e-05,
      "loss": 0.064,
      "step": 18500
    },
    {
      "epoch": 12.541254125412541,
      "grad_norm": 1.0213960409164429,
      "learning_rate": 3.733333333333334e-05,
      "loss": 0.0628,
      "step": 19000
    },
    {
      "epoch": 12.871287128712872,
      "grad_norm": 0.945148229598999,
      "learning_rate": 3.568316831683168e-05,
      "loss": 0.0703,
      "step": 19500
    },
    {
      "epoch": 13.0,
      "eval_loss": 3.982858180999756,
      "eval_runtime": 12.7004,
      "eval_samples_per_second": 26.535,
      "eval_steps_per_second": 6.693,
      "step": 19695
    },
    {
      "epoch": 13.201320132013201,
      "grad_norm": 0.9014415740966797,
      "learning_rate": 3.403300330033004e-05,
      "loss": 0.0572,
      "step": 20000
    },
    {
      "epoch": 13.531353135313532,
      "grad_norm": 0.5070602893829346,
      "learning_rate": 3.238283828382838e-05,
      "loss": 0.0561,
      "step": 20500
    },
    {
      "epoch": 13.861386138613861,
      "grad_norm": 3.1118357181549072,
      "learning_rate": 3.073267326732673e-05,
      "loss": 0.061,
      "step": 21000
    },
    {
      "epoch": 14.0,
      "eval_loss": 4.127552032470703,
      "eval_runtime": 12.7101,
      "eval_samples_per_second": 26.514,
      "eval_steps_per_second": 6.688,
      "step": 21210
    },
    {
      "epoch": 14.191419141914192,
      "grad_norm": 1.1003204584121704,
      "learning_rate": 2.9082508250825087e-05,
      "loss": 0.0506,
      "step": 21500
    },
    {
      "epoch": 14.521452145214521,
      "grad_norm": 0.9771397113800049,
      "learning_rate": 2.743234323432343e-05,
      "loss": 0.0496,
      "step": 22000
    },
    {
      "epoch": 14.851485148514852,
      "grad_norm": 0.46985167264938354,
      "learning_rate": 2.5785478547854787e-05,
      "loss": 0.0555,
      "step": 22500
    },
    {
      "epoch": 15.0,
      "eval_loss": 4.1890482902526855,
      "eval_runtime": 12.6844,
      "eval_samples_per_second": 26.568,
      "eval_steps_per_second": 6.701,
      "step": 22725
    },
    {
      "epoch": 15.181518151815181,
      "grad_norm": 1.0874149799346924,
      "learning_rate": 2.4135313531353137e-05,
      "loss": 0.048,
      "step": 23000
    },
    {
      "epoch": 15.511551155115512,
      "grad_norm": 0.4567015767097473,
      "learning_rate": 2.2485148514851488e-05,
      "loss": 0.0435,
      "step": 23500
    },
    {
      "epoch": 15.841584158415841,
      "grad_norm": 0.7048764824867249,
      "learning_rate": 2.0834983498349835e-05,
      "loss": 0.0514,
      "step": 24000
    },
    {
      "epoch": 16.0,
      "eval_loss": 4.3567705154418945,
      "eval_runtime": 12.7011,
      "eval_samples_per_second": 26.533,
      "eval_steps_per_second": 6.692,
      "step": 24240
    },
    {
      "epoch": 16.17161716171617,
      "grad_norm": 0.6343814134597778,
      "learning_rate": 1.9184818481848186e-05,
      "loss": 0.0447,
      "step": 24500
    },
    {
      "epoch": 16.501650165016503,
      "grad_norm": 0.4959178566932678,
      "learning_rate": 1.753795379537954e-05,
      "loss": 0.0395,
      "step": 25000
    },
    {
      "epoch": 16.831683168316832,
      "grad_norm": 0.695961058139801,
      "learning_rate": 1.588778877887789e-05,
      "loss": 0.0468,
      "step": 25500
    },
    {
      "epoch": 17.0,
      "eval_loss": 4.4596781730651855,
      "eval_runtime": 12.7592,
      "eval_samples_per_second": 26.412,
      "eval_steps_per_second": 6.662,
      "step": 25755
    },
    {
      "epoch": 17.16171617161716,
      "grad_norm": 0.5281426310539246,
      "learning_rate": 1.4237623762376236e-05,
      "loss": 0.0409,
      "step": 26000
    },
    {
      "epoch": 17.49174917491749,
      "grad_norm": 0.6299663782119751,
      "learning_rate": 1.2587458745874589e-05,
      "loss": 0.0362,
      "step": 26500
    },
    {
      "epoch": 17.821782178217823,
      "grad_norm": 0.45714154839515686,
      "learning_rate": 1.0937293729372937e-05,
      "loss": 0.0419,
      "step": 27000
    },
    {
      "epoch": 18.0,
      "eval_loss": 4.473707675933838,
      "eval_runtime": 12.6983,
      "eval_samples_per_second": 26.539,
      "eval_steps_per_second": 6.694,
      "step": 27270
    },
    {
      "epoch": 18.151815181518153,
      "grad_norm": 0.446361780166626,
      "learning_rate": 9.287128712871288e-06,
      "loss": 0.0383,
      "step": 27500
    },
    {
      "epoch": 18.48184818481848,
      "grad_norm": 0.6089209318161011,
      "learning_rate": 7.636963696369637e-06,
      "loss": 0.0332,
      "step": 28000
    },
    {
      "epoch": 18.81188118811881,
      "grad_norm": 0.6943472623825073,
      "learning_rate": 5.986798679867988e-06,
      "loss": 0.0376,
      "step": 28500
    },
    {
      "epoch": 19.0,
      "eval_loss": 4.544534683227539,
      "eval_runtime": 12.7273,
      "eval_samples_per_second": 26.479,
      "eval_steps_per_second": 6.679,
      "step": 28785
    },
    {
      "epoch": 19.141914191419144,
      "grad_norm": 0.2060004025697708,
      "learning_rate": 4.336633663366337e-06,
      "loss": 0.0342,
      "step": 29000
    },
    {
      "epoch": 19.471947194719473,
      "grad_norm": 0.37353265285491943,
      "learning_rate": 2.6864686468646864e-06,
      "loss": 0.0303,
      "step": 29500
    },
    {
      "epoch": 19.801980198019802,
      "grad_norm": 0.5511173605918884,
      "learning_rate": 1.0363036303630364e-06,
      "loss": 0.0319,
      "step": 30000
    },
    {
      "epoch": 20.0,
      "eval_loss": 4.656666278839111,
      "eval_runtime": 12.6851,
      "eval_samples_per_second": 26.567,
      "eval_steps_per_second": 6.701,
      "step": 30300
    },
    {
      "epoch": 20.0,
      "step": 30300,
      "total_flos": 2.5478181009830707e+17,
      "train_loss": 0.2749476944259291,
      "train_runtime": 8975.7857,
      "train_samples_per_second": 6.749,
      "train_steps_per_second": 3.376
    }
  ],
  "logging_steps": 500,
  "max_steps": 30300,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 20,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.5478181009830707e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
